version: "3.9"
services:
  chainlit:
    build: ./chainlit
    container_name: chainlit
    ports:
      - "8501:8501"
    environment:
      OLLAMA_HOST: ollama_app
      OLLAMA_PORT: "11411"
      OPENAI_API_KEY: #a remettre
    depends_on:
      - ollama_app

  ollama_app:
    build: ./ollama
    container_name: ollama_app
    ports:
      - "11411:11411"  # on mappe le port conteneur 11411 sur l’hôte 11411
    volumes:
      - ./ollama/models:/root/.ollama/models # Emplacement du modèle Llama
